{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a705d20",
   "metadata": {},
   "source": [
    "# Lab1 â€” PyTorch Foundations for Computer Vision\n",
    "\n",
    "**Course**: Deep Learning for Image Analysis \n",
    "\n",
    "**Class**: M2 IASD App  \n",
    "\n",
    "**Professor**: Mehyar MLAWEH\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives\n",
    "By the end of this lab, you should be able to:\n",
    "\n",
    "- Understand how **neurons and layers** are implemented in PyTorch\n",
    "- Manipulate **tensors** and reason about shapes\n",
    "- Use **autograd** to compute gradients\n",
    "- Implement a **training loop** yourself\n",
    "- Connect theory (neurons, loss, backprop) to actual code\n",
    "\n",
    "âš ï¸ This notebook is **intentionally incomplete**.  \n",
    "Whenever you see **`# TODO`**, you are expected to write code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07470cd",
   "metadata": {},
   "source": [
    "\n",
    "**Deadline:** ðŸ—“ï¸ **Saturday, February 7th (23:59)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60119f3a",
   "metadata": {},
   "source": [
    "## ðŸ¤– A small (honest) note before you start\n",
    "\n",
    "Letâ€™s be real for a second.\n",
    "\n",
    " I know you **can use LLMs (ChatGPT, Copilot, Claude, etc.)** to help you with this lab.  \n",
    "And yes, **I use them too**, so donâ€™t worry ðŸ˜„\n",
    "\n",
    "ðŸ‘‰ **You are allowed to use AI tools.**  \n",
    "But hereâ€™s the deal:\n",
    "\n",
    "- Donâ€™t just **copyâ€“paste** code you donâ€™t understand  \n",
    "- Take time to **read, question, and modify** what the model gives you  \n",
    "- If you can solve a block **by yourself, without AI**, thatâ€™s excellent \n",
    "\n",
    "Remember:\n",
    "\n",
    "> AI can write code for you, but **only you can understand it** â€” and understanding is what matters for exams, projects, and real work.\n",
    "\n",
    "Use these tools **as assistants, not as replacements for thinking**.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š Useful documentation (highly recommended)\n",
    "\n",
    "You will often find answers faster (and more reliably) by checking the official documentation:\n",
    "\n",
    "- **PyTorch main documentation**  \n",
    "  https://pytorch.org/docs/stable/index.html\n",
    "\n",
    "- **PyTorch tensors**  \n",
    "  https://pytorch.org/docs/stable/tensors.html\n",
    "\n",
    "- **Neural network modules (`torch.nn`)**  \n",
    "  https://pytorch.org/docs/stable/nn.html\n",
    "\n",
    "- **Loss functions** (`BCEWithLogitsLoss`, CrossEntropy, etc.)  \n",
    "  https://pytorch.org/docs/stable/nn.html#loss-functions\n",
    "\n",
    "- **Optimizers** (`SGD`, `Adam`, â€¦)  \n",
    "  https://pytorch.org/docs/stable/optim.html\n",
    "\n",
    "If you learn how to **navigate the documentation**, you are already thinking like a real AI engineer ðŸ‘Œ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f278eff5",
   "metadata": {},
   "source": [
    "## PART I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de614322",
   "metadata": {},
   "source": [
    "## 0) Colab setup â€” GPU check\n",
    "\n",
    "**Instructions**\n",
    "1. In Colab: `Runtime â†’ Change runtime type to GPU T4` \n",
    "2. Select **GPU**\n",
    "3. Save and restart runtime\n",
    "\n",
    "Then run the cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72e3ba23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cu126\n",
      "CUDA available: True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "#TODO: set the device correctly (cuda if available, else cpu)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc7ceb1",
   "metadata": {},
   "source": [
    "## 1) Imports and reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0ce2798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7c326873a350>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# TODO: fix the random seed for reproducibility\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9349f5a5",
   "metadata": {},
   "source": [
    "## 2) PyTorch tensors and shapes\n",
    "\n",
    "Tensors are multi-dimensional arrays that support:\n",
    "- GPU acceleration\n",
    "- automatic differentiation\n",
    "\n",
    "Understanding **shapes** is critical in deep learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2998b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a shape: torch.Size([3])\n",
      "b shape: torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "# Examples\n",
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "b = torch.randn(4, 5)\n",
    "\n",
    "print(\"a shape:\", a.shape)\n",
    "print(\"b shape:\", b.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d675977",
   "metadata": {},
   "source": [
    "### ðŸ” Question (answer inside the markdown)\n",
    "- How many dimensions does tensor `b` have?\n",
    "- What does each dimension represent conceptually?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f876bb",
   "metadata": {},
   "source": [
    "b has two dimensions.\n",
    "Each line represents an individuals and each column a feature of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea0588f",
   "metadata": {},
   "source": [
    "### âœ…Tensor operations\n",
    "\n",
    "Complete the following:\n",
    "\n",
    "1. Create a tensor `x` of shape `(8, 3)` with random values  \n",
    "2. Compute:\n",
    "   - the **mean of each column**\n",
    "   - the **L2 norm of each row**\n",
    "3. Normalize `x` **row-wise** using the L2 norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b4629e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3]) torch.Size([3]) torch.Size([8]) torch.Size([8, 3])\n"
     ]
    }
   ],
   "source": [
    "# TODO: create x\n",
    "x = torch.randn(8, 3)\n",
    "\n",
    "# TODO: column mean\n",
    "col_mean = x.mean(dim=0)\n",
    "\n",
    "# TODO: row-wise L2 norm\n",
    "row_norm = x.norm(p=2, dim=1)\n",
    "\n",
    "# TODO: normalized tensor\n",
    "x_normalized = x / (row_norm.unsqueeze(1) + 1e-8)\n",
    "\n",
    "print(x.shape, col_mean.shape, row_norm.shape, x_normalized.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0f8928",
   "metadata": {},
   "source": [
    "## 3) Artificial neuron â€” from math to code\n",
    "\n",
    "A neuron computes:\n",
    "\n",
    "$$\n",
    "z = \\sum_i w_i x_i + b\n",
    "$$\n",
    "\n",
    "Then applies an activation function:\n",
    "\n",
    "$$\n",
    "y = g(z)\n",
    "$$\n",
    "\n",
    "This section connects directly to the theory seen in class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6d271c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.8000)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1.0, -2.0, 3.0])\n",
    "w = torch.tensor([0.2, 0.4, -0.1])\n",
    "b = torch.tensor(0.1)\n",
    "\n",
    "z = torch.sum(x * w) + b\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2d7490",
   "metadata": {},
   "source": [
    "### Activation functions\n",
    "\n",
    "1. Implement **ReLU**\n",
    "2. Implement **Sigmoid**\n",
    "3. Apply both to `z` and compare the outputs\n",
    "\n",
    "Which activation preserves negative values?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f307df40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(0.3100))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "def relu(z):\n",
    "    return torch.maximum(torch.tensor(0.0), z)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + torch.exp(-z))\n",
    "\n",
    "y_relu = relu(z)\n",
    "y_sigmoid = sigmoid(z)\n",
    "y_relu, y_sigmoid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e764019",
   "metadata": {},
   "source": [
    "## 4) Autograd and gradients\n",
    "\n",
    "PyTorch uses **automatic differentiation** to compute gradients\n",
    "using the **chain rule** (backpropagation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "50f1aab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.890000104904175\n",
      "grad w: tensor([-3.4000, -6.8000,  3.4000])\n",
      "grad b: tensor(-3.4000)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0, 2.0, -1.0], requires_grad=True)\n",
    "w = torch.tensor([0.5, -0.3, 0.8], requires_grad=True)\n",
    "b = torch.tensor(0.2, requires_grad=True)\n",
    "\n",
    "z = torch.sum(x * w) + b\n",
    "loss = (z - 1.0) ** 2\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(\"loss:\", loss.item())\n",
    "print(\"grad w:\", w.grad)\n",
    "print(\"grad b:\", b.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2c78a9",
   "metadata": {},
   "source": [
    "### ðŸ” Conceptual question\n",
    "\n",
    "- If `b.grad > 0`, should `b` increase or decrease after a gradient descent step?\n",
    "Explain **why** in one sentence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38715441",
   "metadata": {},
   "source": [
    "It should decrease because we apply the gradient descent's formula which is : b = b - grad_b * alpha_t with alpha_t > 0 the learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bdee3e",
   "metadata": {},
   "source": [
    "## 5) Toy classification dataset\n",
    "\n",
    "We create a **linearly separable** dataset.\n",
    "\n",
    "Label rule:\n",
    "- class = 1 if `xâ‚ + xâ‚‚ + xâ‚ƒ > 0`\n",
    "- else class = 0\n",
    "\n",
    "This mimics a very simple classification problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "15c8bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generate a dataset of size N=500 with 3 features\n",
    "X = torch.randn(500, 3)\n",
    "y = (torch.sum(X, dim=1) > 0).float()\n",
    "\n",
    "# TODO: split into train (80%) and validation (20%)\n",
    "train_size = int(0.8 * X.shape[0])\n",
    "X_train, X_val = X[:train_size], X[train_size:]\n",
    "y_train, y_val = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c16fc2",
   "metadata": {},
   "source": [
    "## 6) Model definition\n",
    "\n",
    "We define a small **MLP** (fully-connected network):\n",
    "\n",
    "`3 â†’ 16 â†’ 8 â†’ 1`\n",
    "\n",
    "Activation: ReLU  \n",
    "Output: raw logits (no sigmoid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d7b69f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=3, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=8, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# TODO: create model and move it to the GPU \n",
    "model = MLP()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c13b2d2",
   "metadata": {},
   "source": [
    "###  parameters\n",
    "\n",
    "1. Compute **by hand** the total number of parameters\n",
    "2. Verify your answer using PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6168e4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual count: 209\n",
      "PyTorch count: 209\n"
     ]
    }
   ],
   "source": [
    "# TODO: count parameters with PyTorch\n",
    "total_params_manual = 3 * 16 + 16 + 16 * 8 + 8 + 8 * 1 + 1\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(\"Manual count:\", total_params_manual)\n",
    "print(\"PyTorch count:\", total_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f204fb",
   "metadata": {},
   "source": [
    "## 7) Training loop \n",
    "\n",
    "You must complete the full training loop:\n",
    "- forward pass\n",
    "- loss computation\n",
    "- backward pass\n",
    "- optimizer step\n",
    "\n",
    "Loss: `BCEWithLogitsLoss`\n",
    "Optimizer: `SGD`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d80ad2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | loss = 0.7006815671920776\n",
      "Epoch 5 | loss = 0.6826688051223755\n",
      "Epoch 10 | loss = 0.6627987623214722\n",
      "Epoch 15 | loss = 0.6406792998313904\n",
      "Epoch 20 | loss = 0.6144785284996033\n",
      "Epoch 25 | loss = 0.5832680463790894\n",
      "Epoch 30 | loss = 0.5466195344924927\n",
      "Epoch 35 | loss = 0.5044291019439697\n",
      "Epoch 40 | loss = 0.45812201499938965\n",
      "Epoch 45 | loss = 0.4103253185749054\n",
      "Epoch 50 | loss = 0.3635922074317932\n",
      "Epoch 55 | loss = 0.32014164328575134\n",
      "Epoch 60 | loss = 0.28147804737091064\n",
      "Epoch 65 | loss = 0.24821636080741882\n",
      "Epoch 70 | loss = 0.22020456194877625\n",
      "Epoch 75 | loss = 0.19692149758338928\n",
      "Epoch 80 | loss = 0.17761117219924927\n",
      "Epoch 85 | loss = 0.16155460476875305\n",
      "Epoch 90 | loss = 0.1481115072965622\n",
      "Epoch 95 | loss = 0.13669680058956146\n",
      "Epoch 100 | loss = 0.12695583701133728\n",
      "Epoch 105 | loss = 0.11857117712497711\n",
      "Epoch 110 | loss = 0.11131421476602554\n",
      "Epoch 115 | loss = 0.10496898740530014\n",
      "Epoch 120 | loss = 0.09938684105873108\n",
      "Epoch 125 | loss = 0.09442509710788727\n",
      "Epoch 130 | loss = 0.08998428285121918\n",
      "Epoch 135 | loss = 0.0859915018081665\n",
      "Epoch 140 | loss = 0.08237683773040771\n",
      "Epoch 145 | loss = 0.07908732444047928\n",
      "Epoch 150 | loss = 0.07607441395521164\n",
      "Epoch 155 | loss = 0.07330586016178131\n",
      "Epoch 160 | loss = 0.07075652480125427\n",
      "Epoch 165 | loss = 0.06839602440595627\n",
      "Epoch 170 | loss = 0.06620440632104874\n",
      "Epoch 175 | loss = 0.06416291743516922\n",
      "Epoch 180 | loss = 0.06225560978055\n",
      "Epoch 185 | loss = 0.06046947464346886\n",
      "Epoch 190 | loss = 0.05879629775881767\n",
      "Epoch 195 | loss = 0.057224445044994354\n"
     ]
    }
   ],
   "source": [
    "# TODO: move data to device\n",
    "X_train_d = X_train.to(device)\n",
    "y_train_d = y_train.to(device)\n",
    "X_val_d = X_val.to(device)\n",
    "y_val_d = y_val.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # TODO: forward\n",
    "    logits = model(X_train_d)\n",
    "\n",
    "    # TODO: loss\n",
    "    loss = criterion(logits.squeeze(), y_train_d)\n",
    "\n",
    "    # TODO: backward\n",
    "    loss.backward()\n",
    "\n",
    "    # TODO: update\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"Epoch\", epoch, \"| loss =\", float(loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c894744",
   "metadata": {},
   "source": [
    "## 8) Evaluation\n",
    "\n",
    "1. Apply `sigmoid` to the logits\n",
    "2. Convert probabilities to predictions\n",
    "3. Compute **accuracy** on the validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b10b706c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: evaluation\n",
    "with torch.no_grad():\n",
    "    logits = model(X_val_d)\n",
    "    probs = torch.sigmoid(logits)\n",
    "    preds = (probs > 0.5).float().squeeze()\n",
    "    accuracy = (preds == y_val_d).float().mean()\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9698541c",
   "metadata": {},
   "source": [
    "## 9) Reflection questions (answer inside the markdown)\n",
    "\n",
    "1. Why do we **not** apply sigmoid inside the model?\n",
    "2. What would happen if we removed all ReLU activations?\n",
    "3. How does this toy problem relate to image classification?\n",
    "\n",
    "Write short answers (2â€“3 lines each).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e4ee57",
   "metadata": {},
   "source": [
    "1. It's only for rescaling the output between 0 and 1, we already add non-linearity with ReLU function.\n",
    "2. We would have a simple linear regressor.\n",
    "3. We want to do the same type of classification with images, so with more complicated patterns and more classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9f2ed3",
   "metadata": {},
   "source": [
    "## 10) Bridge to Computer Vision\n",
    "\n",
    "So far:\n",
    "- inputs = vectors of size 3\n",
    "- layers = fully-connected\n",
    "\n",
    "Next session:\n",
    "- inputs = images `(B, C, H, W)`\n",
    "- layers = convolutions\n",
    "- same training logic\n",
    "\n",
    "ðŸ‘‰ **Architecture changes, learning principles stay the same.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f479aad6",
   "metadata": {},
   "source": [
    "## Part II â€” Training on MNIST\n",
    "\n",
    "Check the next notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
